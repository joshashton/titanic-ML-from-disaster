{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9483fdb6-f0e5-4ebb-9800-bdb2c59a66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e21b4-cffd-4b00-aa83-79a8536aa075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/powerBITrain.csv\")\n",
    "train = pd.read_csv(\"data/powerBITrain.csv\")\n",
    "test = pd.read_csv(\"data/powerBITest.csv\")\n",
    "\n",
    "# Load original test data (which has the correct order of PassengerId)\n",
    "originaltest = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Sort the test dataframe to match originaltest if needed (assuming index might differ)\n",
    "test = test.sort_values(by='PassengerId', ascending=True)\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d123d88c-4625-4ae7-a4ba-ccdac28a4db2",
   "metadata": {},
   "source": [
    "### Encode objects and fill blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aebfb0c-8096-4bb5-83de-a80f7be74edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping Ticket by frequency\n",
    "#train set\n",
    "encodedTicket = train.groupby('Ticket').size() / len(train)\n",
    "train.loc[:, \"EncodedTicket\"] = train['Ticket'].map(encodedTicket)\n",
    "#test set\n",
    "encodedTicket = test.groupby('Ticket').size() / len(test)\n",
    "test.loc[:, \"EncodedTicket\"] = test['Ticket'].map(encodedTicket)\n",
    "\n",
    "#Grouping Sex by binary encoding\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Sex' column\n",
    "#train set\n",
    "train['SexBinary'] = label_encoder.fit_transform(train['Sex'])\n",
    "#test set\n",
    "test['SexBinary'] = label_encoder.fit_transform(test['Sex'])\n",
    "\n",
    "#Grouping Embarked by one hot encoding\n",
    "#fill 2 null values with mode before encoding \n",
    "embarked_mode = train['Embarked'].mode()[0]  # Calculate mode\n",
    "train['Embarked'].fillna(embarked_mode, inplace=True)  # Fill NaNs with mode\n",
    "\n",
    "#train set\n",
    "train = pd.get_dummies(train, columns=['Embarked'], prefix='Embarked', drop_first=False)\n",
    "#test set\n",
    "test = pd.get_dummies(test, columns=['Embarked'], prefix='Embarked', drop_first=False)\n",
    "\n",
    "# change title from object to int\n",
    "encodedTitle = train.groupby('Title').size() / len(train)\n",
    "train.loc[:, \"encodedTitle\"] = train['Title'].map(encodedTitle)\n",
    "#test set\n",
    "encodedTitle = test.groupby('Title').size() / len(test)\n",
    "test.loc[:, \"encodedTitle\"] = test['Title'].map(encodedTitle)\n",
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1bfb19-881a-4d3a-a5fe-0070b9c01077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make train and test features the same\n",
    "train.drop([\"Survived\", \"PassengerId\", \"Sex\", \"Ticket\",\"Parch\", \"SibSp\", \"Title\"], axis=1, inplace=True)\n",
    "test.drop([\"PassengerId\",\"Sex\", \"Ticket\",\"Parch\", \"SibSp\", \"Title\"], axis=1, inplace=True)\n",
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00308d91-8dd9-4c02-88c6-e5336278f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 712 entries, 0 to 711\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Age            712 non-null    float64\n",
      " 1   FamilyCount    712 non-null    float64\n",
      " 2   Fare           712 non-null    float64\n",
      " 3   Pclass         712 non-null    float64\n",
      " 4   EncodedTicket  712 non-null    float64\n",
      " 5   SexBinary      712 non-null    float64\n",
      " 6   Embarked_C     712 non-null    float64\n",
      " 7   Embarked_Q     712 non-null    float64\n",
      " 8   Embarked_S     712 non-null    float64\n",
      " 9   encodedTitle   712 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 55.8 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Age            418 non-null    float64\n",
      " 1   FamilyCount    418 non-null    float64\n",
      " 2   Fare           418 non-null    float64\n",
      " 3   Pclass         418 non-null    float64\n",
      " 4   EncodedTicket  418 non-null    float64\n",
      " 5   SexBinary      418 non-null    float64\n",
      " 6   Embarked_C     418 non-null    float64\n",
      " 7   Embarked_Q     418 non-null    float64\n",
      " 8   Embarked_S     418 non-null    float64\n",
      " 9   encodedTitle   418 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 32.8 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>FamilyCount</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>EncodedTicket</th>\n",
       "      <th>SexBinary</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>encodedTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.7417</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0042</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  FamilyCount     Fare  Pclass  EncodedTicket  SexBinary  Embarked_C  \\\n",
       "0  0.0          1.0   8.5167     3.0       0.213483        1.0         1.0   \n",
       "1  1.0          2.0  15.7417     3.0       0.213483        0.0         1.0   \n",
       "2  1.0          2.0  37.0042     2.0       0.078652        1.0         1.0   \n",
       "3  1.0          3.0  19.2583     3.0       0.213483        0.0         1.0   \n",
       "4  1.0          3.0  19.2583     3.0       0.213483        0.0         1.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  encodedTitle  \n",
       "0         0.0         0.0      0.050562  \n",
       "1         0.0         0.0      0.203652  \n",
       "2         0.0         0.0      0.050562  \n",
       "3         0.0         0.0      0.203652  \n",
       "4         0.0         0.0      0.203652  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#terative imputer\n",
    "imputer = IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        random_state=0,\n",
    "        n_nearest_features=3,\n",
    "        max_iter=20,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "train_imputed = imputer.fit_transform(train)\n",
    "test_imputed = imputer.fit_transform(test)\n",
    "\n",
    "# Convert imputed values back to DataFrame\n",
    "train = pd.DataFrame(train_imputed, columns=train.columns)\n",
    "test = pd.DataFrame(test_imputed, columns=test.columns)\n",
    "\n",
    "#No null values\n",
    "#only features to be used are in DF\n",
    "print(train.info())\n",
    "print(test.info())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123df4c-a66f-4cc3-98fc-941f26a16667",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1746253-12d8-4c02-8ac1-c47aefb14811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and testing sets\n",
    "X = train.values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# All models to apply\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=10000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=0),\n",
    "    \"Support Vector Machine\": SVC(random_state=0),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(random_state=0, objective='binary:logistic')\n",
    "}\n",
    "\n",
    "# Models' hyperparameters for grid search\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": [\n",
    "        {\n",
    "            'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'logisticregression__penalty': ['l1', 'l2'],\n",
    "            'logisticregression__solver': ['liblinear']\n",
    "        },\n",
    "        {\n",
    "            'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'logisticregression__penalty': ['l2'],\n",
    "            'logisticregression__solver': ['lbfgs']\n",
    "        }\n",
    "    ],\n",
    "    \"Decision Tree\": {\n",
    "        'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "        'decisiontreeclassifier__max_depth': [None, 5, 10, 20, 30],\n",
    "        'decisiontreeclassifier__min_samples_split': [2, 5, 10],\n",
    "        'decisiontreeclassifier__min_samples_leaf': [1, 2, 4],\n",
    "        'decisiontreeclassifier__max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'randomforestclassifier__n_estimators': [100, 200],\n",
    "        'randomforestclassifier__max_depth': [2, 4, 5, 8],\n",
    "        'randomforestclassifier__min_samples_split': [2, 5, 10],\n",
    "        'randomforestclassifier__min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "        'randomforestclassifier__max_features': ['sqrt', 'log2', None],\n",
    "        'randomforestclassifier__bootstrap': [True, False]\n",
    "    },\n",
    "    \"Support Vector Machine\": {\n",
    "            'svc__C': [0.1, 1, 10, 100],\n",
    "            'svc__kernel': ['linear']\n",
    "    },\n",
    "    \"K-Nearest Neighbors\": {\n",
    "        'kneighborsclassifier__n_neighbors': [3, 5, 7, 10],\n",
    "        'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "        'kneighborsclassifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'kneighborsclassifier__p': [1, 2]  # p=1 for Manhattan distance, p=2 for Euclidean distance\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'xgbclassifier__n_estimators': [50, 100, 200, 300],\n",
    "        'xgbclassifier__max_depth': [3, 4, 5, 6],\n",
    "        'xgbclassifier__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "        'xgbclassifier__subsample': [0.5, 0.7, 1],\n",
    "        'xgbclassifier__colsample_bytree': [0.5, 0.7, 1],\n",
    "        'xgbclassifier__gamma': [0, 0.1, 0.2, 0.3]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "288b8f45-949f-4f0c-95b5-bd76c4f0e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Highest Accuracy: 0.808\n",
      "Training Decision Tree...\n",
      "Highest Accuracy: 0.821\n",
      "Training Random Forest...\n",
      "Highest Accuracy: 0.84\n",
      "Training Support Vector Machine...\n",
      "Highest Accuracy: 0.798\n",
      "Training K-Nearest Neighbors...\n",
      "Highest Accuracy: 0.731\n",
      "Training XGBoost...\n",
      "Highest Accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "#Loop through models and perform GridSearchCV\n",
    "#Remove model names in front of parameter names from grid search\n",
    "def strip_prefix(param_dict):\n",
    "    return {key.split(\"_\", 2)[-1]: value for key, value in param_dict.items()}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    #pipeline\n",
    "    pipeline = make_pipeline(model)\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grids[name], scoring='accuracy', cv=5, n_jobs=4)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    # Strip the prefixes for other models use\n",
    "    best_parameters = strip_prefix(grid_search.best_params_)\n",
    "    \n",
    "    best_models[name] = {\n",
    "        \"best_accuracy\": best_accuracy,\n",
    "        \"best_parameters\": best_parameters\n",
    "    }\n",
    "    print(f\"Highest Accuracy: {round(best_models[name]['best_accuracy'], 3)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e8d732-addb-4db6-9f54-06f9bc1c9245",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d696d865-52fc-4ad5-acf4-d974b52d6fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "#Apply best model to test set \n",
    "originaltest = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "#Get best grid searched model\n",
    "model = models['XGBoost']\n",
    "best_params = best_models['XGBoost']['best_parameters']\n",
    "model.set_params(**best_params)\n",
    "\n",
    "#Predict model from whole test set\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(test.values)\n",
    "\n",
    "try:\n",
    "    output = pd.DataFrame({'PassengerId': originaltest.PassengerId, 'Survived': predictions})\n",
    "    output.to_csv('data/submissionV2.csv', index=False)\n",
    "except Exception:\n",
    "    print(\"Failed to save csv\")\n",
    "else:\n",
    "    print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af4ebe-6125-4630-84f3-a6ba303fed12",
   "metadata": {},
   "source": [
    "Current submission score = 0.76076"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
